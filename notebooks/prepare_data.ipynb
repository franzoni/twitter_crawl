{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare data for training\n",
    "\n",
    "1. Load all embeddings\n",
    "1. Tokenize tweets\n",
    "1. Construct embdding matrix matchin the tokenizer\n",
    "1. Generate sequences\n",
    "1. Write everything to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/musella/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"../python\")\n",
    "\n",
    "import utils\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_words = 2500\n",
    "glove_dim = 25\n",
    "hash_dim = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_embed = utils.load_glove_embedding(utils.glove_embedding_path(25))\n",
    "hash_embed = utils.load_glove_embedding('../data/models/hashtags/hash_vectors.d'+str(hash_dim)+'.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_hdf(\"../data/preproc/tweets.hd5\")\n",
    "\n",
    "tk = Tokenizer(num_words=max_words,\n",
    "               filters=\"\", # already applied\n",
    "               lower=True,\n",
    "               split=\" \",oov_token=\"<unk>\")\n",
    "tk.fit_on_texts(df[\"preproc_text\"]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(utils)\n",
    "words_embed_mtx, words_unk = utils.fill_embedding_matrix(tk.word_index,words_embed,max_words,glove_dim)\n",
    "hash_embed_mtx, hash_unk = utils.fill_embedding_matrix(tk.word_index,hash_embed,max_words,hash_dim)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'h2o': 1862, 'datasciencectrl': 1469, 'kirkdborne': 500, 'poptimize': 809, 'chatbot': 1064, 'ipfconline1': 550, 'interpretability': 1302, 'machinelearning': 484, 'classifier': 2366, 'vanloon': 151, 'neurips': 563, 'datascience': 2044, 'chatbots': 941, 'variational': 2489, 'nodexl': 1582, 'probabilistic': 1747, 'piccard': 2495, 'deeplearn007': 818, 'evankirstel': 808, 'spirosmargaris': 784, 'daysofmlcode': 864, 'fisher85m': 900, 'jblefevre60': 1195, 'bengio': 1871, 'bodyproblem': 1749, 'kaggle': 2058, 'daysofcode': 527, 'antgrasso': 1135, 'freshsalis': 1337, 'whova': 664, 'cloudexpo': 2386, 'alphazero': 2420, 'jimmarous': 1258, 'automl': 1844, 'mikequindazzi': 165, 'neurips2018': 2312, 'pulipaka': 1554, 'v1': 925, 'convolutional': 859, 'pierrepinna': 2295, 'kdnuggets': 931, 'sagemaker': 2346, '<stop>': 5, 'ahier': 1381, 'analyticbridge': 2394, 'tensorflow': 348, 'pytorch': 1658, 'intengineering': 2352, 'scikit': 1692, 'datax': 2458}\n"
     ]
    }
   ],
   "source": [
    "unk = { word: tk.word_index[word] for word in set(words_unk).intersection(set(hash_unk)) }\n",
    "print(unk)\n",
    "\n",
    "stop_mtx = np.zeros( (max_words+2, 2) )\n",
    "\n",
    "# stop_mtx[unk.pop(\"<trunc>\"),-2] = 1.\n",
    "stop_mtx[unk.pop(\"<stop>\"),-1] = 1.\n",
    "\n",
    "stop_mtx[list(unk.values()),-2] = 1.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ahier': 1381,\n",
       " 'alphazero': 2420,\n",
       " 'analyticbridge': 2394,\n",
       " 'antgrasso': 1135,\n",
       " 'automl': 1844,\n",
       " 'bengio': 1871,\n",
       " 'bodyproblem': 1749,\n",
       " 'chatbot': 1064,\n",
       " 'chatbots': 941,\n",
       " 'classifier': 2366,\n",
       " 'cloudexpo': 2386,\n",
       " 'convolutional': 859,\n",
       " 'datascience': 2044,\n",
       " 'datasciencectrl': 1469,\n",
       " 'datax': 2458,\n",
       " 'daysofcode': 527,\n",
       " 'daysofmlcode': 864,\n",
       " 'deeplearn007': 818,\n",
       " 'evankirstel': 808,\n",
       " 'fisher85m': 900,\n",
       " 'freshsalis': 1337,\n",
       " 'h2o': 1862,\n",
       " 'intengineering': 2352,\n",
       " 'interpretability': 1302,\n",
       " 'ipfconline1': 550,\n",
       " 'jblefevre60': 1195,\n",
       " 'jimmarous': 1258,\n",
       " 'kaggle': 2058,\n",
       " 'kdnuggets': 931,\n",
       " 'kirkdborne': 500,\n",
       " 'machinelearning': 484,\n",
       " 'mikequindazzi': 165,\n",
       " 'neurips': 563,\n",
       " 'neurips2018': 2312,\n",
       " 'nodexl': 1582,\n",
       " 'piccard': 2495,\n",
       " 'pierrepinna': 2295,\n",
       " 'poptimize': 809,\n",
       " 'probabilistic': 1747,\n",
       " 'pulipaka': 1554,\n",
       " 'pytorch': 1658,\n",
       " 'sagemaker': 2346,\n",
       " 'scikit': 1692,\n",
       " 'spirosmargaris': 784,\n",
       " 'tensorflow': 348,\n",
       " 'v1': 925,\n",
       " 'vanloon': 151,\n",
       " 'variational': 2489,\n",
       " 'whova': 664}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unk_idx = list(unk.values())\n",
    "unk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.isnan(words_embed_mtx).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.isnan(hash_embed_mtx).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "! mkdir ../data/models/sequences\n",
    "\n",
    "import pickle\n",
    "import json\n",
    "\n",
    "\n",
    "with open(\"../data/models/sequences/info.json\",\"w+\") as out:\n",
    "    save = dict(max_words=max_words,unk_idx=unk_idx)\n",
    "    out.write(json.dumps(save))\n",
    "    \n",
    "with open('../data/models/sequences/tokenizer.pkl','wb+') as out:\n",
    "    out.write( pickle.dumps(tk) )\n",
    "    \n",
    "np.save('../data/models/sequences/embed_mtx.npy',words_embed_mtx)\n",
    "np.save('../data/models/sequences/hash_mtx.npy',hash_embed_mtx)\n",
    "np.save('../data/models/sequences/hash_mtx.npy',stop_mtx)\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/musella/anaconda3/lib/python3.6/site-packages/pandas/core/generic.py:1471: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block2_values] [items->['extended_tweet/full_text', 'lang', 'retweeted_status/extended_tweet/full_text', 'text', 'user/name', 'preproc_text', 'sequences']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df[\"sequences\"] = tk.texts_to_sequences(df[\"preproc_text\"])\n",
    "\n",
    "df.to_hdf(\"../data/preproc/sequences.hd5\",\"squences\",columns=[\"sequences\"],mode=\"w\")\n",
    "\n",
    "# index = np.arange(df.index.shape[0]).astype(np.int)\n",
    "# train_idx, test_idx = train_test_split(index,test_size=0.2,random_state=123456)\n",
    "# df_train = df.iloc[train_idx]\n",
    "# df_test = df.iloc[test_idx]\n",
    "# df_train.to_hdf(\"../data/preproc/sequences.hd5\",\"train\",columns=[\"sequences\"])\n",
    "# df_test.to_hdf(\"../data/preproc/sequences.hd5\",\"test\",columns=[\"sequences\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('#neurips2018 attendees, a new discussion on \"HCI and monitization in A.I.\" was just started. Join the conversation on the Whova app! https://t.co/VZVHTRVN4U',\n",
       "  '<hashtag> #neurips2018 attendees a new discussion on <unk> and <unk> in a i was just started join the conversation on the whova app <url> <stop>'),\n",
       " ('Interesting stats about my #NeurIPS2018 tweets! People mostly tend to check the NeurIPS tweets exactly after the conf. (8-10PM, 1st col.) or just before the day starts (6-8Am, 6th col.)  \\U0001f928 https://t.co/a7aFg4g7na',\n",
       "  'interesting stats about my <hashtag> #neurips2018 tweets people mostly <unk> to check the neurips tweets exactly after the <unk> <number> <number> pm <number> st <unk> or just before the day starts <number> <number> am <number> th <unk> <url> <stop>'),\n",
       " ('Jordan Gruber @j2g2_ : Our robot \"Marvin\" can count and identify asbestos particles - this can cut costs to $15 - versus $50 - per analysis. @FrontierMicro  #DeepLearning #innovation #artificialintelligence #machinelearning #data #datascience #aicn',\n",
       "  '<unk> <unk> <user> our robot <unk> can <unk> and identify <unk> <unk> this can cut costs to <number> <unk> <number> per analysis <user> <hashtag> #deeplearning <hashtag> #innovation <hashtag> #artificialintelligence <hashtag> #machinelearning <hashtag> #data <hashtag> #datascience <hashtag> <unk> <stop>'),\n",
       " (\"What are Hypergiant's big ambitions for an intelligent future all about? Check out @MyABJ discussing machine intelligence and the ways we are spreading it: https://t.co/ZuOleYXVc8\\n\\n#meethypergiant #tomorrowingtoday #machinelearning #evolution #humanity\",\n",
       "  'what are <unk> s big <unk> for an intelligent future all about check out <user> discussing machine intelligence and the ways we are <unk> it <url> <hashtag> <unk> <hashtag> <unk> <hashtag> #machinelearning <hashtag> <unk> <hashtag> <unk> <stop>'),\n",
       " ('RT @hsianghui: Zero-shot learning: Using text to accurately ID images #facebook #ai #machinelearning https://t.co/ovzzhvPMVu',\n",
       "  'rt <user> zero <unk> learning using text to accurately <unk> images <hashtag> #facebook <hashtag> #ai <hashtag> #machinelearning <url> <stop>'),\n",
       " ('#arXiv #machinelearning [cs.LG] Time-Discounting Convolution for Event Sequences with Ambiguous Timestamps. (arXiv:1812.02395v1 [cs.LG]) https://t.co/QgqNhemxbq\\n\\nThis paper proposes a method for modeling event sequences with ambiguous timestamps, a time-discounting convolution.…',\n",
       "  '<hashtag> #arxiv <hashtag> #machinelearning cs lg time <unk> <unk> for event <unk> with <unk> <unk> arxiv <number> v1 cs lg <url> this paper <unk> a method for modeling event <unk> with <unk> <unk> a time <unk> <stop>'),\n",
       " ('How automation could free up millions of hours of federal employee time - Federal News Network https://t.co/SM6bfq5XIu via @FederalNewsNet @nogryskoWFED #ArtificialIntelligence #automation #AI #MachineLearning',\n",
       "  'how automation could free up millions of hours of federal employee time federal news network <url> via <user> <user> <hashtag> #artificialintelligence <hashtag> #automation <hashtag> #ai <hashtag> #machinelearning <stop>'),\n",
       " ('For those within climate or the enthusiast, this will surely bring a smile &amp; spark an interest to learn more of this innovation.  @Ronald_vanLoon \\n#solarenergy \\n\\n@IntEngineering',\n",
       "  'for those within climate or the <unk> this will <unk> bring a <unk> amp spark an interest to learn more of this innovation <user> <hashtag> <unk> <user> <stop>'),\n",
       " ('#arXiv #machinelearning [cs.LG] Top-K Off-Policy Correction for a REINFORCE Recommender System. (arXiv:1812.02353v1 [cs.LG]) https://t.co/BEgAHIQOas\\n\\nIndustrial recommender systems deal with extremely large action spaces -- many millions of items to recommend. Moreover, they ne…',\n",
       "  '<hashtag> #arxiv <hashtag> #machinelearning cs lg top k off policy <unk> for a <unk> <unk> system arxiv <number> v1 cs lg <url> industrial <unk> systems deal with <unk> large action <unk> many millions of items to <unk> <unk> they <stop>'),\n",
       " ('via @RichardEudes - How Lawyers will be Killed by the Blockchain and not Machine\\xa0Learning https://t.co/eiqzfia9GQ #blockchain, #businessanalytics, #datascience, #machinelearning https://t.co/Fp7zV5xKu1',\n",
       "  'via <user> how <unk> will be <unk> by the blockchain and not machine learning <url> <hashtag> #blockchain <hashtag> #businessanalytics <hashtag> #datascience <hashtag> #machinelearning <url> <stop>'),\n",
       " ('This would be helpful to understand what really happens (sort of ;))',\n",
       "  'this would be <unk> to understand what really happens <unk> of <stop>'),\n",
       " ('So many #machinelearning use cases at the Quad today! Rajeev Dutt from @DMInc_AI shares yet another: auto-generating new types of pharmaceutical drugs. #reInvent https://t.co/Qye5uzP5el',\n",
       "  'so many <hashtag> #machinelearning use cases at the <unk> today <unk> <unk> from <user> shares yet another auto generating new types of <unk> <unk> <hashtag> #reinvent <url> <stop>'),\n",
       " ('Way to go Steve', 'way to go <unk> <stop>'),\n",
       " ('RT @ZoeGeop: RT @ZoeGeop: RT @ZoeGeop: RT @ZoeGeop: RT @ZoeGeop: RT @ZoeGeop: RT @SatyaJalluri: RT @ZoeGeop: RT @theChrisChua: RT @godfrey_rono: Are we ready to hand over our hairstyles to #Robots? #AI barber. #machinelearning @HaroldSinnott @MikeQuindaz… https://t.co/acxMK3ptHg',\n",
       "  'rt <user> rt <user> rt <user> rt <user> rt <user> rt <user> rt <user> rt <user> rt <user> rt <user> are we ready to hand over our <unk> to <hashtag> #robots <hashtag> #ai <unk> <hashtag> #machinelearning <user> <url> <stop>'),\n",
       " ('Cloud Computing News &amp; Views: https://t.co/KndnWeMyVE #ai #machinelearning',\n",
       "  'cloud computing news amp <unk> <url> <hashtag> #ai <hashtag> #machinelearning <stop>'),\n",
       " ('How Popular #SearchEngines Will Evolve in the #artificialintelligence Process \\n\\n  https://t.co/TaNy7czmeu\\n\\n#bigdata #machinelearning #AI #machineintelligence #technology #Singularity #IoT #deeplearning #deepmind #MariaJohnsen https://t.co/mE8I8u9wvo',\n",
       "  'how popular <hashtag> <unk> will <unk> in the <hashtag> #artificialintelligence process <url> <hashtag> #bigdata <hashtag> #machinelearning <hashtag> #ai <hashtag> #machineintelligence <hashtag> #technology <hashtag> <unk> <hashtag> #iot <hashtag> #deeplearning <hashtag> #deepmind <hashtag> #mariajohnsen <url> <stop>'),\n",
       " ('#DesignThinking &amp; #MachineLearning {Infographic}\\n\\n[@jblefevre60 @cloudpreacher]\\n#ML #DataScience @Fisher85M #BigData #IoT #UX #CX #AI #fintech https://t.co/dZ4LKG0SNM',\n",
       "  '<hashtag> #designthinking amp <hashtag> #machinelearning infographic <user> <user> <hashtag> #ml <hashtag> #datascience <user> <hashtag> #bigdata <hashtag> #iot <hashtag> #ux <hashtag> #cx <hashtag> #ai <hashtag> #fintech <url> <stop>'),\n",
       " ('.@PLOSMedicine #MachineLearning Special Issue Guest Eds @suchisaria, @atulbutte &amp; @DrAzizSheikh cut through the hyperbole with an accessible and accurate portrayal of the forefront of machine learning in clinical translation\\nhttps://t.co/IiMwzjMMvn',\n",
       "  '<user> <hashtag> #machinelearning special issue guest <unk> <user> <user> amp <user> cut through the <unk> with an accessible and accurate <unk> of the <unk> of machine learning in clinical translation <url> <stop>'),\n",
       " (\"Meet us at #KubeCon + #CloudNativeCon, booth S/E 43. We're demonstrating how to snapshot, version, package, distribute and share whole environments (code + libs + data) across teams and locations\\n#kubernetes #k8s #kubeflow #DataScience #MachineLearning #datamanagement #workflow https://t.co/mG8o2agQ4n\",\n",
       "  'meet us at <hashtag> #kubecon <hashtag> <unk> booth s e <number> we are <unk> how to <unk> version package <unk> and share whole environments code <unk> data across teams and <unk> <hashtag> #kubernetes <hashtag> <unk> <hashtag> <unk> <hashtag> #datascience <hashtag> #machinelearning <hashtag> #datamanagement <hashtag> <unk> <url> <stop>'),\n",
       " ('Data Science in Visual Studio Code using Neuron, a new VS Code extension – Microsoft Faculty Connection https://t.co/Eqi1AcmpZ9 #AI #DeepLearning #MachineLearning #DataScience https://t.co/gnvZHctjXa',\n",
       "  'data science in visual studio code using <unk> a new vs code <unk> microsoft <unk> <unk> <url> <hashtag> #ai <hashtag> #deeplearning <hashtag> #machinelearning <hashtag> #datascience <url> <stop>')]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list( zip(df.iloc[:20][\"text\"],tk.sequences_to_texts( tk.texts_to_sequences(df.iloc[:20][\"preproc_text\"]) )) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ?tk.texts_to_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1]]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tk.texts_to_sequences( [\"<unk>\"] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tk.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
