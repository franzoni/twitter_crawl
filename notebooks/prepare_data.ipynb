{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"../python\")\n",
    "\n",
    "import utils\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_words = 2400\n",
    "glove_dim = 25\n",
    "hash_dim = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_embed = utils.load_glove_embedding(utils.glove_embedding_path(25))\n",
    "hash_embed = utils.load_glove_embedding('../data/models/hashtags/hash_vectors.d'+str(hash_dim)+'.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_hdf(\"../data/preproc/tweets.hd5\")\n",
    "\n",
    "tk = Tokenizer(num_words=max_words,\n",
    "               filters=\"\", # already applied\n",
    "               lower=True,\n",
    "               split=\" \",oov_token=\"<unk>\")\n",
    "tk.fit_on_texts(df[\"preproc_text\"]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(utils)\n",
    "words_embed_mtx, words_unk = utils.fill_embedding_matrix(tk.word_index,words_embed,max_words,glove_dim)\n",
    "hash_embed_mtx, hash_unk = utils.fill_embedding_matrix(tk.word_index,hash_embed,max_words,hash_dim)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'kaggle': 1388, 'rtit': 2330, 'nodexl': 1138, 'h2o': 1581, 'spirosmargaris': 1401, 'verisk': 1778, 'insurtech': 1838, '#rvp': 1717, '#domains': 1376, 'jupyter': 2162, 'chatbot': 794, '#nvidia': 2260, 'yape': 2165, '#sensor': 2171, 'kdnuggets': 965, '#machineintelligence': 2096, '#cfo': 2135, '#meetup': 2307, 'convolutional': 671, 'bytedance': 2371, 'kubernetes': 2253, 'interpretability': 1229, 'daysofcode': 2067, 'daysofmlcode': 1263, 'neurips': 467, '#mqtt': 2276, 'autoencoders': 2080, 'mikequindazzi': 182, 'pytorch': 1392, '#neuralnetwork': 1855, 'pierrepinna': 2313, 'ipfconline1': 1343, 'whova': 661, 'scikit': 1878, '#india': 1695, 'automl': 1819, 'intengineering': 2275, 'datascience': 1792, 'granvilledsc': 2140, '<stop>': 3, 'classifier': 2315, 'classifiers': 2362, '#ravivisvesvarayasharadaprasad': 1718, '#fraud': 2196, 'analyticbridge': 2226, 'machinelearning': 509, 'neurips2018': 1754, 'kirkdborne': 635, 'v1': 1311, 'cnewsuae': 2329, 'variational': 1627, 'datasciencectrl': 1218, '#li': 1624, 'tensorflow': 291, 'ethereum': 2139, 'deeplearn007': 1649, '#manufacturing': 2185, 'dimensionality': 2219, 'alphazero': 2161, 'jimmarous': 1994, 'probabilistic': 1411, '#aiethics': 2187, 'poptimize': 758, 'chatbots': 705, 'overfitting': 2386, '#article': 2227, 'vanloon': 100, 'datax': 1724, 'bengio': 1853, 'pulipaka': 778, 'sagemaker': 1974, '#ksql': 2170, '#language': 2367, '#techiegeeks': 1960, '#ceo': 2078, 'fisher85m': 1069, 'serverless': 2063, '#cios': 2394, '#jupyter': 2273}\n"
     ]
    }
   ],
   "source": [
    "unk = { word: tk.word_index[word] for word in set(words_unk).intersection(set(hash_unk)) }\n",
    "print(unk)\n",
    "\n",
    "stop_mtx = np.zeros( (max_words+2, 2) )\n",
    "\n",
    "# stop_mtx[unk.pop(\"<trunc>\"),-2] = 1.\n",
    "stop_mtx[unk.pop(\"<stop>\"),-1] = 1.\n",
    "\n",
    "stop_mtx[list(unk.values()),-2] = 1.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'#aiethics': 2187,\n",
       " '#article': 2227,\n",
       " '#ceo': 2078,\n",
       " '#cfo': 2135,\n",
       " '#cios': 2394,\n",
       " '#domains': 1376,\n",
       " '#fraud': 2196,\n",
       " '#india': 1695,\n",
       " '#jupyter': 2273,\n",
       " '#ksql': 2170,\n",
       " '#language': 2367,\n",
       " '#li': 1624,\n",
       " '#machineintelligence': 2096,\n",
       " '#manufacturing': 2185,\n",
       " '#meetup': 2307,\n",
       " '#mqtt': 2276,\n",
       " '#neuralnetwork': 1855,\n",
       " '#nvidia': 2260,\n",
       " '#ravivisvesvarayasharadaprasad': 1718,\n",
       " '#rvp': 1717,\n",
       " '#sensor': 2171,\n",
       " '#techiegeeks': 1960,\n",
       " 'alphazero': 2161,\n",
       " 'analyticbridge': 2226,\n",
       " 'autoencoders': 2080,\n",
       " 'automl': 1819,\n",
       " 'bengio': 1853,\n",
       " 'bytedance': 2371,\n",
       " 'chatbot': 794,\n",
       " 'chatbots': 705,\n",
       " 'classifier': 2315,\n",
       " 'classifiers': 2362,\n",
       " 'cnewsuae': 2329,\n",
       " 'convolutional': 671,\n",
       " 'datascience': 1792,\n",
       " 'datasciencectrl': 1218,\n",
       " 'datax': 1724,\n",
       " 'daysofcode': 2067,\n",
       " 'daysofmlcode': 1263,\n",
       " 'deeplearn007': 1649,\n",
       " 'dimensionality': 2219,\n",
       " 'ethereum': 2139,\n",
       " 'fisher85m': 1069,\n",
       " 'granvilledsc': 2140,\n",
       " 'h2o': 1581,\n",
       " 'insurtech': 1838,\n",
       " 'intengineering': 2275,\n",
       " 'interpretability': 1229,\n",
       " 'ipfconline1': 1343,\n",
       " 'jimmarous': 1994,\n",
       " 'jupyter': 2162,\n",
       " 'kaggle': 1388,\n",
       " 'kdnuggets': 965,\n",
       " 'kirkdborne': 635,\n",
       " 'kubernetes': 2253,\n",
       " 'machinelearning': 509,\n",
       " 'mikequindazzi': 182,\n",
       " 'neurips': 467,\n",
       " 'neurips2018': 1754,\n",
       " 'nodexl': 1138,\n",
       " 'overfitting': 2386,\n",
       " 'pierrepinna': 2313,\n",
       " 'poptimize': 758,\n",
       " 'probabilistic': 1411,\n",
       " 'pulipaka': 778,\n",
       " 'pytorch': 1392,\n",
       " 'rtit': 2330,\n",
       " 'sagemaker': 1974,\n",
       " 'scikit': 1878,\n",
       " 'serverless': 2063,\n",
       " 'spirosmargaris': 1401,\n",
       " 'tensorflow': 291,\n",
       " 'v1': 1311,\n",
       " 'vanloon': 100,\n",
       " 'variational': 1627,\n",
       " 'verisk': 1778,\n",
       " 'whova': 661,\n",
       " 'yape': 2165}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unk_idx = list(unk.values())\n",
    "unk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.isnan(words_embed_mtx).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.isnan(hash_embed_mtx).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! mkdir ../data/models/sequences\n",
    "\n",
    "import pickle\n",
    "import json\n",
    "\n",
    "with open(\"../data/models/sequences/info.json\",\"w+\") as out:\n",
    "    save = dict(max_words=max_words,unk_idx=unk_idx)\n",
    "    out.write(json.dumps(save))\n",
    "    \n",
    "with open('../data/models/sequences/tokenizer.pkl','wb+') as out:\n",
    "    out.write( pickle.dumps(tk) )\n",
    "    \n",
    "np.save('../data/models/sequences/embed_mtx.npy',words_embed_mtx)\n",
    "np.save('../data/models/sequences/hash_mtx.npy',hash_embed_mtx)\n",
    "np.save('../data/models/sequences/hash_mtx.npy',stop_mtx)\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/musella/anaconda3/lib/python3.6/site-packages/pandas/core/generic.py:1471: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block2_values] [items->['lang', 'text', 'user/name', 'preproc_text', 'sequences']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df[\"sequences\"] = tk.texts_to_sequences(df[\"preproc_text\"])\n",
    "\n",
    "df.to_hdf(\"../data/preproc/sequences.hd5\",\"squences\",columns=[\"sequences\"],mode=\"w\")\n",
    "\n",
    "# index = np.arange(df.index.shape[0]).astype(np.int)\n",
    "# train_idx, test_idx = train_test_split(index,test_size=0.2,random_state=123456)\n",
    "# df_train = df.iloc[train_idx]\n",
    "# df_test = df.iloc[test_idx]\n",
    "# df_train.to_hdf(\"../data/preproc/sequences.hd5\",\"train\",columns=[\"sequences\"])\n",
    "# df_test.to_hdf(\"../data/preproc/sequences.hd5\",\"test\",columns=[\"sequences\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('#neurips2018 attendees, a new discussion on \"HCI and monitization in A.I.\" was just started. Join the conversation… https://t.co/zftGzImYQ0',\n",
       "  '<hashtag> #neurips2018 attendees a new discussion on <unk> and <unk> in a i was just started join the <url> <stop>'),\n",
       " ('Interesting stats about my #NeurIPS2018 tweets! People mostly tend to check the NeurIPS tweets exactly after the co… https://t.co/PQk31bTpDb',\n",
       "  'interesting stats about my <hashtag> #neurips2018 tweets people mostly <unk> to check the neurips tweets exactly after the <url> <stop>'),\n",
       " ('Jordan Gruber @j2g2_ : Our robot \"Marvin\" can count and identify asbestos particles - this can cut costs to $15 - v… https://t.co/0o2iWrPkYL',\n",
       "  '<unk> <unk> <user> our robot <unk> can <unk> and identify <unk> <unk> this can cut costs to <number> <url> <stop>'),\n",
       " (\"RT @hypergiant: What are Hypergiant's big ambitions for an intelligent future all about? Check out @MyABJ discussing machine intelligence a…\",\n",
       "  'rt <user> what are <unk> s big <unk> for an intelligent future all about check out <user> discussing machine intelligence <stop>'),\n",
       " ('RT @IntelAIDev: Spotlight Paper at #NeurIPS2018: \"Norm Matters: Efficient and Accurate Normalization Schemes in Deep Networks” poster sessi…',\n",
       "  'rt <user> spotlight paper at <hashtag> #neurips2018 <unk> matters efficient and accurate <unk> <unk> in deep networks poster <stop>'),\n",
       " ('Happy to see a ScaledML 2018 talk by Andrej @Karpathy cited in the #NeurIPS2018 keynote by Kunle. Would you like to… https://t.co/ESkUcEQwbA',\n",
       "  'happy to see a <unk> <number> talk by <unk> <user> <unk> in the <hashtag> #neurips2018 keynote by kunle would you like <url> <stop>'),\n",
       " ('RT @hsianghui: Zero-shot learning: Using text to accurately ID images #facebook #ai #machinelearning https://t.co/ovzzhvPMVu',\n",
       "  'rt <user> zero <unk> learning using text to accurately <unk> images <hashtag> #facebook <hashtag> #ai <hashtag> #machinelearning <url> <stop>'),\n",
       " ('#arXiv #machinelearning [cs.LG] Time-Discounting Convolution for Event Sequences with Ambiguous Timestamps. (arXiv:… https://t.co/hEV2WtFYdX',\n",
       "  '<hashtag> #arxiv <hashtag> #machinelearning cs lg time <unk> <unk> for event <unk> with <unk> <unk> <url> <stop>'),\n",
       " ('RT @jgustavob: How automation could free up millions of hours of federal employee time - Federal News Network https://t.co/SM6bfq5XIu via @…',\n",
       "  'rt <user> how automation could free up millions of hours of federal employee time federal news network <url> via <stop>'),\n",
       " ('For those within climate or the enthusiast, this will surely bring a smile &amp; spark an interest to learn more of thi… https://t.co/FDnyc8vBLB',\n",
       "  'for those within climate or the <unk> this will <unk> bring a <unk> amp spark an interest to learn more of <url> <stop>'),\n",
       " ('#arXiv #machinelearning [cs.LG] dynnode2vec: Scalable Dynamic Network Embedding. (arXiv:1812.02356v1 [cs.LG])… https://t.co/Ty3kWcggT4',\n",
       "  '<hashtag> #arxiv <hashtag> #machinelearning cs lg <unk> scalable <unk> network embedding arxiv <number> v1 <url> <stop>'),\n",
       " ('RT @DataScientistsF: via @RichardEudes - How Lawyers will be Killed by the Blockchain and not Machine\\xa0Learning https://t.co/eiqzfia9GQ #blo…',\n",
       "  'rt <user> via <user> how <unk> will be killed by the blockchain and not machine learning <url> <stop>'),\n",
       " ('This would be helpful to understand what really happens (sort of ;))',\n",
       "  'this would be <unk> to understand what really happens sort of <stop>'),\n",
       " ('RT @AICollaborative: Jordan Gruber @j2g2_ , CEO &amp; Founder of @FrontierMicro, with Marvin, the first automated microscope which can analyse…',\n",
       "  'rt <user> <unk> <unk> <user> ceo amp founder of <user> with <unk> the first automated <unk> which can <stop>'),\n",
       " ('RT @jeffclune: My invited talk tomorrow at the Deep RL workshop (now at 4pm) will describe/motivate/defend/discuss Go-Explore (our new hard…',\n",
       "  'rt <user> my invited talk tomorrow at the deep rl workshop now at <number> pm will describe <unk> <unk> discuss go explore our new <stop>'),\n",
       " ('Way to go Steve', 'way to go steve <stop>'),\n",
       " ('RT @lastlineinc: “Surveylance”, a tool developed by a Northeastern University PhD student, determines that 90% of online #surveys are fraud…',\n",
       "  'rt <user> <unk> a tool developed by a <unk> university phd student <unk> that <number> of online <hashtag> <unk> are <stop>'),\n",
       " ('Cloud Computing News &amp; Views: https://t.co/KndnWeMyVE #ai #machinelearning',\n",
       "  'cloud computing news amp views <url> <hashtag> #ai <hashtag> #machinelearning <stop>'),\n",
       " ('RT @boostsites: How Popular #SearchEngines Will Evolve in the #artificialintelligence Process \\n\\n  https://t.co/TaNy7czmeu\\n\\n#bigdata #machin…',\n",
       "  'rt <user> how popular <hashtag> <unk> will <unk> in the <hashtag> #artificialintelligence process <url> <hashtag> #bigdata <stop>'),\n",
       " ('RT @iebs_gurgaon: #DesignThinking &amp; #MachineLearning {Infographic}\\n\\n[@jblefevre60 @cloudpreacher]\\n#ML #DataScience @Fisher85M #BigData #IoT…',\n",
       "  'rt <user> <hashtag> #designthinking amp <hashtag> #machinelearning infographic <user> <user> <hashtag> #ml <hashtag> #datascience <user> <hashtag> #bigdata <stop>')]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list( zip(df.iloc[:20][\"text\"],tk.sequences_to_texts( tk.texts_to_sequences(df.iloc[:20][\"preproc_text\"]) )) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ?tk.texts_to_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1]]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tk.texts_to_sequences( [\"<unk>\"] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tk.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
